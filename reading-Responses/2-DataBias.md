<!-- Reading Response 2 -- Data Bias -- 0221 -- Tina-->
- For such a long time, countless people have devoted themselves to diminish discrimination, however, it still exists in the world, just around us. So, why does discrimination appear, and how does it develop? I owe this to "absoluteness". It is natural for us human beings to categorise and summarise the things we observe. The summarisation itself is nothing bad but helpful and great. However, we should always keep in mind that "large quantity" does not stand for "all", and that "high possibility" can never represent "must". For instance, if all friends who do IT wear a plaid shirt, I can summarise that IT around like wearing plaid shirts, or deduce that probably most IT like wearing plaid shirts. But once this deduction is expressed with absolute words, for instance, "All IT must like wearing plaid shirts", then this simple helpful summarisation skill becomes the lens of stereotype we put on that negatively impact our recognition and interaction towards others. When the subject people focus on becomes more severe, such as assuming all black people are more likely to become criminals, the simple stereotype ultimately forms discrimination. Also, there are other historical factors behind the formation of discrimination, but it is needless to say that absoluteness amplifies the extend.
- I feel so sad about the story the TED talk guest told us. I have never realised that this unfairness is such severe existing in the coding world. And the unconsciousness about the existence of the bias problem is what horrifies me. If we say that in ancient times, emperors are absolute authorities, then computers and algorithms are the emperors in our times. However, no matter how Authoritative emperors are in ancient times, as long as they are human beings, there will finally exist a day that the sun they represent falls, and there will always exist opposition. However, it is a completely different discourse when it comes to us vs computers. We have different sensing, thinking, decision-making, etc systems in comparison with computers, making it hard to understand and fully explain how computers work, needless to say, let computers know how we exactly think and act. However, the natural property of computers, always having the same answers when giving the same conditions, makes us unconsciously and unconditionally believe that computers are fair enough. This belief is naturally rooted in our minds, making us believe that all decisions computers made should be correct. In this way, we lose the context and lose our judgment. We rely too much on data, computers, and algorithms. I believe and I hope that someday these things can be fixed to be more correct and should be applied to fields that can help increase fairness, but I also strongly hold the belief that we should never rely only on data, instead, we should always keep skeptical and critical. This is also how I understand the sentence "The state doesn't need a cop to kill a person" and "electronic incarceration".
- Lastly, about some recent examples in China. One I can think of is the trip code. This code is used to check the provinces you have been stayed in for 14 days and will show if those places are medium/high risk. The algorithm behind this trip code is to record where we are through the phone calls we made. However, this code does not seem to work for all. One of my friends just cannot refresh and generate her trip code while I can simply have the trip code. The weirdest thing is that neither of us has made a phone call in 14 days. I did not know the exact bug behind this, but it shows the drawback of algorithms, and is reminding us that we should not depend too much on data and algorithms. 
